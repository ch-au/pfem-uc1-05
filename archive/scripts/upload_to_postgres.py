#!/usr/bin/env python3
"""
Copy the contents of the generated SQLite archive into a Neon Postgres instance.

Usage:
    python upload_to_postgres.py --sqlite fsv_archive_complete.db
    python upload_to_postgres.py --sqlite fsv_archive_complete.db --postgres "<dsn>"
    
If --postgres is not provided, DB_URL will be loaded from .env file.
"""

import argparse
import os
import sqlite3
import sys
from contextlib import closing
from typing import Dict, Iterable, List, Sequence, Tuple
from datetime import datetime

import psycopg2
from psycopg2 import sql
from psycopg2.extras import execute_values
from dotenv import load_dotenv

# Load environment variables from .env
load_dotenv()


TABLE_DDL: Dict[str, str] = {
    "teams": """
        CREATE TABLE IF NOT EXISTS public.teams (
            team_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            name TEXT UNIQUE,
            normalized_name TEXT UNIQUE,
            team_type TEXT,
            profile_url TEXT
        );
    """,
    "competitions": """
        CREATE TABLE IF NOT EXISTS public.competitions (
            competition_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            name TEXT UNIQUE,
            normalized_name TEXT UNIQUE,
            level TEXT,
            gender TEXT
        );
    """,
    "seasons": """
        CREATE TABLE IF NOT EXISTS public.seasons (
            season_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            label TEXT UNIQUE,
            start_year INTEGER,
            end_year INTEGER,
            team_id INTEGER REFERENCES public.teams(team_id)
        );
    """,
    "season_competitions": """
        CREATE TABLE IF NOT EXISTS public.season_competitions (
            season_competition_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            season_id INTEGER REFERENCES public.seasons(season_id),
            competition_id INTEGER REFERENCES public.competitions(competition_id),
            stage_label TEXT,
            source_path TEXT,
            UNIQUE (season_id, competition_id)
        );
    """,
    "referees": """
        CREATE TABLE IF NOT EXISTS public.referees (
            referee_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            name TEXT UNIQUE,
            normalized_name TEXT UNIQUE,
            profile_url TEXT
        );
    """,
    "coaches": """
        CREATE TABLE IF NOT EXISTS public.coaches (
            coach_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            name TEXT UNIQUE,
            normalized_name TEXT UNIQUE,
            birth_date DATE,
            birth_place TEXT,
            nationality TEXT,
            profile_url TEXT
        );
    """,
    "coach_careers": """
        CREATE TABLE IF NOT EXISTS public.coach_careers (
            career_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            coach_id INTEGER REFERENCES public.coaches(coach_id) ON DELETE CASCADE,
            team_name TEXT,
            start_date TEXT,
            end_date TEXT,
            role TEXT
        );
    """,
    "players": """
        CREATE TABLE IF NOT EXISTS public.players (
            player_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            name TEXT UNIQUE,
            normalized_name TEXT UNIQUE,
            birth_date DATE,
            birth_place TEXT,
            height_cm INTEGER,
            weight_kg INTEGER,
            primary_position TEXT,
            nationality TEXT,
            profile_url TEXT,
            image_url TEXT
        );
    """,
    "player_aliases": """
        CREATE TABLE IF NOT EXISTS public.player_aliases (
            alias_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            player_id INTEGER REFERENCES public.players(player_id) ON DELETE CASCADE,
            alias TEXT,
            normalized_alias TEXT,
            UNIQUE (player_id, normalized_alias)
        );
    """,
    "player_careers": """
        CREATE TABLE IF NOT EXISTS public.player_careers (
            career_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            player_id INTEGER REFERENCES public.players(player_id) ON DELETE CASCADE,
            team_name TEXT,
            start_year INTEGER,
            end_year INTEGER,
            notes TEXT
        );
    """,
    "season_squads": """
        CREATE TABLE IF NOT EXISTS public.season_squads (
            season_squad_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            season_competition_id INTEGER REFERENCES public.season_competitions(season_competition_id) ON DELETE CASCADE,
            player_id INTEGER REFERENCES public.players(player_id) ON DELETE CASCADE,
            position_group TEXT,
            shirt_number INTEGER,
            status TEXT,
            notes TEXT,
            UNIQUE (season_competition_id, player_id, position_group)
        );
    """,
    "matches": """
        CREATE TABLE IF NOT EXISTS public.matches (
            match_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            season_competition_id INTEGER REFERENCES public.season_competitions(season_competition_id) ON DELETE CASCADE,
            round_name TEXT,
            matchday INTEGER,
            leg INTEGER,
            match_date DATE,
            kickoff_time TEXT,
            venue TEXT,
            attendance INTEGER,
            referee_id INTEGER REFERENCES public.referees(referee_id),
            home_team_id INTEGER REFERENCES public.teams(team_id),
            away_team_id INTEGER REFERENCES public.teams(team_id),
            home_score INTEGER,
            away_score INTEGER,
            halftime_home INTEGER,
            halftime_away INTEGER,
            extra_time_home INTEGER,
            extra_time_away INTEGER,
            penalties_home INTEGER,
            penalties_away INTEGER,
            source_file TEXT,
            UNIQUE (season_competition_id, source_file)
        );
    """,
    "match_coaches": """
        CREATE TABLE IF NOT EXISTS public.match_coaches (
            match_coach_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            match_id INTEGER REFERENCES public.matches(match_id) ON DELETE CASCADE,
            team_id INTEGER REFERENCES public.teams(team_id),
            coach_id INTEGER REFERENCES public.coaches(coach_id),
            role TEXT
        );
    """,
    "match_referees": """
        CREATE TABLE IF NOT EXISTS public.match_referees (
            match_referee_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            match_id INTEGER REFERENCES public.matches(match_id) ON DELETE CASCADE,
            referee_id INTEGER REFERENCES public.referees(referee_id),
            role TEXT
        );
    """,
    "match_lineups": """
        CREATE TABLE IF NOT EXISTS public.match_lineups (
            lineup_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            match_id INTEGER REFERENCES public.matches(match_id) ON DELETE CASCADE,
            team_id INTEGER REFERENCES public.teams(team_id),
            player_id INTEGER REFERENCES public.players(player_id),
            shirt_number INTEGER,
            is_starter BOOLEAN,
            minute_on INTEGER,
            stoppage_on INTEGER,
            minute_off INTEGER,
            stoppage_off INTEGER
        );
    """,
    "match_substitutions": """
        CREATE TABLE IF NOT EXISTS public.match_substitutions (
            substitution_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            match_id INTEGER REFERENCES public.matches(match_id) ON DELETE CASCADE,
            team_id INTEGER REFERENCES public.teams(team_id),
            minute INTEGER,
            stoppage INTEGER,
            player_on_id INTEGER REFERENCES public.players(player_id),
            player_off_id INTEGER REFERENCES public.players(player_id)
        );
    """,
    "goals": """
        CREATE TABLE IF NOT EXISTS public.goals (
            goal_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            match_id INTEGER REFERENCES public.matches(match_id) ON DELETE CASCADE,
            team_id INTEGER REFERENCES public.teams(team_id),
            player_id INTEGER REFERENCES public.players(player_id),
            assist_player_id INTEGER REFERENCES public.players(player_id),
            minute INTEGER,
            stoppage INTEGER,
            score_home INTEGER,
            score_away INTEGER,
            event_type TEXT
        );
    """,
    "cards": """
        CREATE TABLE IF NOT EXISTS public.cards (
            card_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            match_id INTEGER REFERENCES public.matches(match_id) ON DELETE CASCADE,
            team_id INTEGER REFERENCES public.teams(team_id),
            player_id INTEGER REFERENCES public.players(player_id),
            minute INTEGER,
            stoppage INTEGER,
            card_type TEXT
        );
    """,
    "match_notes": """
        CREATE TABLE IF NOT EXISTS public.match_notes (
            note_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            match_id INTEGER REFERENCES public.matches(match_id) ON DELETE CASCADE,
            note TEXT,
            note_type TEXT
        );
    """,
    "season_matchdays": """
        CREATE TABLE IF NOT EXISTS public.season_matchdays (
            season_matchday_id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            season_competition_id INTEGER REFERENCES public.season_competitions(season_competition_id) ON DELETE CASCADE,
            matchday INTEGER,
            date DATE,
            position INTEGER,
            points INTEGER,
            goals_for INTEGER,
            goals_against INTEGER,
            goal_difference INTEGER
        );
    """,
}


TABLE_ORDER: Sequence[Tuple[str, Sequence[str]]] = [
    ("teams", ("team_id", "name", "normalized_name", "team_type", "profile_url")),
    ("competitions", ("competition_id", "name", "normalized_name", "level", "gender")),
    ("seasons", ("season_id", "label", "start_year", "end_year", "team_id")),
    ("season_competitions", ("season_competition_id", "season_id", "competition_id", "stage_label", "source_path")),
    ("referees", ("referee_id", "name", "normalized_name", "profile_url")),
    ("coaches", ("coach_id", "name", "normalized_name", "birth_date", "birth_place", "nationality", "profile_url")),
    ("players", ("player_id", "name", "normalized_name", "birth_date", "birth_place", "height_cm", "weight_kg", "primary_position", "nationality", "profile_url", "image_url")),
    ("player_aliases", ("alias_id", "player_id", "alias", "normalized_alias")),
    ("player_careers", ("career_id", "player_id", "team_name", "start_year", "end_year", "notes")),
    ("coach_careers", ("career_id", "coach_id", "team_name", "start_date", "end_date", "role")),
    ("season_squads", ("season_squad_id", "season_competition_id", "player_id", "position_group", "shirt_number", "status", "notes")),
    ("matches", ("match_id", "season_competition_id", "round_name", "matchday", "leg", "match_date", "kickoff_time", "venue", "attendance", "referee_id", "home_team_id", "away_team_id", "home_score", "away_score", "halftime_home", "halftime_away", "extra_time_home", "extra_time_away", "penalties_home", "penalties_away", "source_file")),
    ("match_coaches", ("match_coach_id", "match_id", "team_id", "coach_id", "role")),
    ("match_referees", ("match_referee_id", "match_id", "referee_id", "role")),
    ("match_lineups", ("lineup_id", "match_id", "team_id", "player_id", "shirt_number", "is_starter", "minute_on", "stoppage_on", "minute_off", "stoppage_off")),
    ("match_substitutions", ("substitution_id", "match_id", "team_id", "minute", "stoppage", "player_on_id", "player_off_id")),
    ("goals", ("goal_id", "match_id", "team_id", "player_id", "assist_player_id", "minute", "stoppage", "score_home", "score_away", "event_type")),
    ("cards", ("card_id", "match_id", "team_id", "player_id", "minute", "stoppage", "card_type")),
    ("match_notes", ("note_id", "match_id", "note", "note_type")),
    ("season_matchdays", ("season_matchday_id", "season_competition_id", "matchday", "date", "position", "points", "goals_for", "goals_against", "goal_difference")),
]


DROP_ORDER: Iterable[str] = [
    "season_matchdays",
    "match_notes",
    "cards",
    "goals",
    "match_substitutions",
    "match_lineups",
    "match_referees",
    "match_coaches",
    "matches",
    "season_squads",
    "coach_careers",
    "player_careers",
    "player_aliases",
    "players",
    "coaches",
    "referees",
    "season_competitions",
    "seasons",
    "competitions",
    "teams",
]


IDENTITY_COLUMNS: Sequence[Tuple[str, str]] = [
    ("teams", "team_id"),
    ("competitions", "competition_id"),
    ("seasons", "season_id"),
    ("season_competitions", "season_competition_id"),
    ("referees", "referee_id"),
    ("coaches", "coach_id"),
    ("players", "player_id"),
    ("player_aliases", "alias_id"),
    ("player_careers", "career_id"),
    ("coach_careers", "career_id"),
    ("season_squads", "season_squad_id"),
    ("matches", "match_id"),
    ("match_coaches", "match_coach_id"),
    ("match_referees", "match_referee_id"),
    ("match_lineups", "lineup_id"),
    ("match_substitutions", "substitution_id"),
    ("goals", "goal_id"),
    ("cards", "card_id"),
    ("match_notes", "note_id"),
    ("season_matchdays", "season_matchday_id"),
]


def fetch_sqlite_rows(conn: sqlite3.Connection, table: str, columns: Sequence[str]) -> List[Tuple]:
    query = f"SELECT {', '.join(columns)} FROM {table}"
    cur = conn.execute(query)
    rows = [tuple(row[idx] for idx in range(len(columns))) for row in cur.fetchall()]
    return rows


def drop_existing_tables(pg_conn) -> None:
    with pg_conn, pg_conn.cursor() as cur:
        for table in DROP_ORDER:
            cur.execute(sql.SQL("DROP TABLE IF EXISTS public.{table} CASCADE;").format(table=sql.Identifier(table)))


def create_schema(pg_conn) -> None:
    with pg_conn, pg_conn.cursor() as cur:
        for table, ddl in TABLE_DDL.items():
            cur.execute(ddl)


def convert_and_validate_dates(table: str, columns: Sequence[str], rows: List[Tuple]) -> List[Tuple]:
    """
    Validate and convert date strings to proper PostgreSQL date format.
    Invalid dates (like "31.09.1972") are set to None.
    """
    from datetime import datetime
    
    # Tables with date columns
    date_columns = {
        "season_matchdays": {"date"},
        "matches": {"match_date"},
        "players": {"birth_date"},
        "coaches": {"birth_date"},
        "coach_careers": {"start_date", "end_date"},
    }
    
    if table not in date_columns:
        return rows
    
    date_cols = date_columns[table]
    if not date_cols:
        return rows
    
    # Find indices of date columns
    date_indices = {i: col for i, col in enumerate(columns) if col in date_cols}
    if not date_indices:
        return rows
    
    # Convert rows
    converted_rows = []
    for row in rows:
        converted_row = list(row)
        for idx, col_name in date_indices.items():
            date_val = converted_row[idx]
            if date_val is not None and isinstance(date_val, str):
                # Skip invalid dates like "31.09.1972"
                try:
                    # Try parsing common formats
                    if "." in date_val:
                        # German format DD.MM.YYYY
                        parts = date_val.split(".")
                        if len(parts) == 3:
                            day, month, year = int(parts[0]), int(parts[1]), int(parts[2])
                            # Validate: month 1-12, day 1-31 (basic check)
                            if month < 1 or month > 12:
                                converted_row[idx] = None
                            elif day < 1 or day > 31:
                                converted_row[idx] = None
                            else:
                                # Try to create date to catch invalid days (e.g., 31.09)
                                try:
                                    datetime(year, month, day)
                                    # Convert to PostgreSQL format
                                    converted_row[idx] = f"{year:04d}-{month:02d}-{day:02d}"
                                except ValueError:
                                    # Invalid date (e.g., 31.09)
                                    converted_row[idx] = None
                        else:
                            converted_row[idx] = None
                    elif "-" in date_val and len(date_val) == 10:
                        # Already in YYYY-MM-DD format
                        try:
                            datetime.strptime(date_val, "%Y-%m-%d")
                            # Keep as is
                        except ValueError:
                            converted_row[idx] = None
                    else:
                        converted_row[idx] = None
                except (ValueError, IndexError, AttributeError):
                    converted_row[idx] = None
        
        converted_rows.append(tuple(converted_row))
    
    return converted_rows


def convert_boolean_columns(table: str, columns: Sequence[str], rows: List[Tuple]) -> List[Tuple]:
    """
    Convert SQLite integer booleans (0/1) to proper Python booleans for Postgres.
    
    SQLite stores booleans as 0/1, but Postgres expects proper boolean types.
    """
    # Define boolean columns for each table
    boolean_columns = {
        "match_lineups": {"is_starter"},
        "season_squads": set(),  # has no boolean columns in the current schema
    }
    
    if table not in boolean_columns:
        return rows
    
    bool_cols = boolean_columns[table]
    if not bool_cols:
        return rows
    
    # Find indices of boolean columns
    bool_indices = {i for i, col in enumerate(columns) if col in bool_cols}
    if not bool_indices:
        return rows
    
    # Convert rows
    converted_rows = []
    for row in rows:
        converted_row = list(row)
        for idx in bool_indices:
            if converted_row[idx] is not None:
                converted_row[idx] = bool(converted_row[idx])
        converted_rows.append(tuple(converted_row))
    
    return converted_rows


def insert_table(pg_conn, table: str, columns: Sequence[str], rows: List[Tuple]) -> None:
    if not rows:
        return
    
    # Convert and validate dates first
    rows = convert_and_validate_dates(table, columns, rows)
    
    # Convert boolean columns from SQLite integers to proper booleans
    rows = convert_boolean_columns(table, columns, rows)
    
    placeholders = sql.SQL(", ").join(sql.Identifier(col) for col in columns)
    insert_stmt = sql.SQL("INSERT INTO public.{table} ({columns}) VALUES %s").format(
        table=sql.Identifier(table),
        columns=placeholders,
    )
    with pg_conn, pg_conn.cursor() as cur:
        execute_values(cur, insert_stmt.as_string(cur), rows, page_size=1000)


def reset_sequences(pg_conn) -> None:
    with pg_conn, pg_conn.cursor() as cur:
        for table, column in IDENTITY_COLUMNS:
            cur.execute(
                sql.SQL(
                    "SELECT setval(pg_get_serial_sequence(%s, %s), COALESCE(MAX({id_col}), 0) + 1, false) FROM {table}"
                ).format(
                    id_col=sql.Identifier(column),
                    table=sql.Identifier("public", table),
                ),
                (f"public.{table}", column),
            )


def create_indexes(pg_conn) -> None:
    """Create performance indexes after data migration."""
    print("Creating indexes...")
    indexes = [
        # Entity lookups
        "CREATE INDEX IF NOT EXISTS idx_teams_normalized_name ON public.teams(normalized_name)",
        "CREATE INDEX IF NOT EXISTS idx_players_normalized_name ON public.players(normalized_name)",
        "CREATE INDEX IF NOT EXISTS idx_players_name ON public.players(name)",
        "CREATE INDEX IF NOT EXISTS idx_coaches_normalized_name ON public.coaches(normalized_name)",
        "CREATE INDEX IF NOT EXISTS idx_referees_normalized_name ON public.referees(normalized_name)",
        
        # Season and competition lookups
        "CREATE INDEX IF NOT EXISTS idx_seasons_label ON public.seasons(label)",
        "CREATE INDEX IF NOT EXISTS idx_seasons_years ON public.seasons(start_year, end_year)",
        "CREATE INDEX IF NOT EXISTS idx_season_competitions_season ON public.season_competitions(season_id)",
        "CREATE INDEX IF NOT EXISTS idx_season_competitions_comp ON public.season_competitions(competition_id)",
        
        # Match queries
        "CREATE INDEX IF NOT EXISTS idx_matches_date ON public.matches(match_date)",
        "CREATE INDEX IF NOT EXISTS idx_matches_season_comp ON public.matches(season_competition_id)",
        "CREATE INDEX IF NOT EXISTS idx_matches_home_team ON public.matches(home_team_id)",
        "CREATE INDEX IF NOT EXISTS idx_matches_away_team ON public.matches(away_team_id)",
        
        # Match events
        "CREATE INDEX IF NOT EXISTS idx_lineups_match ON public.match_lineups(match_id)",
        "CREATE INDEX IF NOT EXISTS idx_lineups_player ON public.match_lineups(player_id)",
        "CREATE INDEX IF NOT EXISTS idx_lineups_team ON public.match_lineups(team_id)",
        "CREATE INDEX IF NOT EXISTS idx_goals_match ON public.goals(match_id)",
        "CREATE INDEX IF NOT EXISTS idx_goals_player ON public.goals(player_id)",
        "CREATE INDEX IF NOT EXISTS idx_goals_assist ON public.goals(assist_player_id)",
        "CREATE INDEX IF NOT EXISTS idx_cards_match ON public.cards(match_id)",
        "CREATE INDEX IF NOT EXISTS idx_cards_player ON public.cards(player_id)",
        "CREATE INDEX IF NOT EXISTS idx_subs_match ON public.match_substitutions(match_id)",
        "CREATE INDEX IF NOT EXISTS idx_subs_player_on ON public.match_substitutions(player_on_id)",
        "CREATE INDEX IF NOT EXISTS idx_subs_player_off ON public.match_substitutions(player_off_id)",
    ]
    
    with pg_conn, pg_conn.cursor() as cur:
        for i, index_sql in enumerate(indexes, 1):
            print(f"  Creating index {i}/{len(indexes)}...", end="\r")
            cur.execute(index_sql)
    print(f"  Created {len(indexes)} indexes successfully!")


def migrate(sqlite_path: str, postgres_dsn: str, wipe: bool = True, create_idx: bool = True) -> None:
    """
    Migrate data from SQLite to Postgres.
    
    Args:
        sqlite_path: Path to SQLite database
        postgres_dsn: Postgres connection string
        wipe: If True, drop existing tables before migration
        create_idx: If True, create performance indexes after migration
    """
    print("=" * 80)
    print("FSV MAINZ 05 DATABASE MIGRATION")
    print("=" * 80)
    print(f"Source (SQLite): {sqlite_path}")
    print(f"Target (Postgres): {postgres_dsn[:50]}...")
    print(f"Wipe existing tables: {wipe}")
    print(f"Create indexes: {create_idx}")
    print(f"Started at: {datetime.now().isoformat()}")
    print("=" * 80)
    print()
    
    sqlite_conn = sqlite3.connect(sqlite_path)
    sqlite_conn.row_factory = sqlite3.Row

    with closing(sqlite_conn), closing(psycopg2.connect(postgres_dsn)) as pg_conn:
        # Step 1: Drop and create schema
        if wipe:
            print("Step 1: Dropping existing tables...")
            drop_existing_tables(pg_conn)
            print("  ✓ Tables dropped")
        
        print("Step 2: Creating schema...")
        create_schema(pg_conn)
        print("  ✓ Schema created")
        print()
        
        # Step 2: Migrate data
        print("Step 3: Migrating data...")
        total_rows = 0
        for i, (table, columns) in enumerate(TABLE_ORDER, 1):
            rows = fetch_sqlite_rows(sqlite_conn, table, columns)
            row_count = len(rows)
            total_rows += row_count
            
            print(f"  [{i:2d}/{len(TABLE_ORDER)}] {table:25s} ... {row_count:6,} rows", end="")
            insert_table(pg_conn, table, columns, rows)
            print(" ✓")
        
        print(f"\n  ✓ Migrated {total_rows:,} total rows")
        print()
        
        # Step 3: Reset sequences
        print("Step 4: Resetting sequences...")
        reset_sequences(pg_conn)
        print("  ✓ Sequences reset")
        print()
        
        # Step 4: Create indexes
        if create_idx:
            print("Step 5: Creating indexes...")
            create_indexes(pg_conn)
            print("  ✓ Indexes created")
            print()
        
    print("=" * 80)
    print(f"✅ MIGRATION COMPLETE!")
    print(f"Finished at: {datetime.now().isoformat()}")
    print(f"Total rows migrated: {total_rows:,}")
    print("=" * 80)


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Copy SQLite archive into Postgres.",
        epilog="If --postgres is not provided, DB_URL will be loaded from .env file."
    )
    parser.add_argument("--sqlite", default="fsv_archive_complete.db", 
                       help="Path to the SQLite database.")
    parser.add_argument("--postgres", help="Postgres DSN/connection string (or use DB_URL in .env)")
    parser.add_argument("--no-wipe", action="store_true", 
                       help="Do not drop existing tables before load.")
    parser.add_argument("--no-indexes", action="store_true",
                       help="Do not create indexes after migration.")
    args = parser.parse_args()
    
    # Get Postgres DSN from args or environment
    postgres_dsn = args.postgres or os.getenv("DB_URL")
    
    if not postgres_dsn:
        print("Error: Postgres DSN not provided!")
        print("  Either pass --postgres argument or set DB_URL in .env file")
        sys.exit(1)
    
    try:
        migrate(args.sqlite, postgres_dsn, wipe=not args.no_wipe, create_idx=not args.no_indexes)
    except Exception as e:
        print(f"\n❌ Migration failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
